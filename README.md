# ğŸ›¡ï¸ Aegis - Intelligent SRE Agent

A comprehensive Site Reliability Engineering (SRE) system that combines Machine Learning anomaly detection, RAG-based knowledge retrieval, and automated mitigation strategies with real-time monitoring and human escalation capabilities.

![SRE Dashboard](https://img.shields.io/badge/Status-Production%20Ready-green)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![ML](https://img.shields.io/badge/ML-Scikit--learn-orange)
![Kafka](https://img.shields.io/badge/Kafka-Streaming-red)
![Twilio](https://img.shields.io/badge/Twilio-Paging-blue)
![SendGrid](https://img.shields.io/badge/SendGrid-Email-green)

## ğŸ¯ Overview

Aegis is an intelligent SRE agent that provides end-to-end automation for detecting, analyzing, and resolving system anomalies in real-time. It combines multiple AI agents working in orchestration to provide intelligent, automated incident response with human oversight for critical issues.

### ğŸ”¥ Key Features

#### ğŸ¤– **Multi-Agent Architecture**
- **Anomaly Detection Agent**: ML-powered real-time anomaly detection using trained models
- **RAG Agent**: Retrieval-Augmented Generation for intelligent knowledge base queries
- **Mitigation Agent**: Automated execution and validation of remediation actions
- **Critical Anomaly Reasoning Agent**: Advanced LLM analysis for complex issues
- **Report Generation Agent**: Automated incident report creation and email delivery
- **Paging Agent**: Human escalation via Twilio phone calls

#### ğŸ§  **Intelligent Processing**
- **Real-time ML Inference**: Continuous anomaly detection using trained models
- **RAG Knowledge Base**: Pre-defined playbooks for common SRE scenarios
- **Validation Simulator**: Risk-free testing of mitigation actions before execution
- **Metrics Tracking**: Comprehensive before/after analysis of all actions
- **Confidence Scoring**: AI-driven confidence levels for all decisions

#### ğŸ“Š **Real-Time Dashboard**
- **Live Log Streaming**: Real-time visualization of system logs
- **Agent Activity Monitoring**: Live status of all SRE agents
- **Anomaly Visualization**: Color-coded log streams (green=normal, red=anomaly)
- **Reasoning Trace**: Step-by-step agent decision process visualization
- **Metrics Graphs**: Real-time system performance metrics
- **Interactive Controls**: Manual anomaly injection for testing

#### ğŸ”§ **Automated Mitigation**
- **Service Restart**: Automatic service recovery
- **Horizontal Scaling**: Load distribution across instances
- **Cache Management**: Memory optimization strategies
- **Connection Pool Management**: Database connection optimization
- **Circuit Breaker**: Fault tolerance implementation
- **Request Throttling**: Rate limiting for overload protection

#### ğŸš¨ **Human Escalation**
- **Critical Issue Detection**: Automatic identification of severe anomalies
- **Email Reports**: Detailed incident reports via SendGrid
- **Phone Paging**: Immediate human notification via Twilio
- **Escalation Workflow**: Automated routing to appropriate teams

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Stream  â”‚â”€â”€â”€â–¶â”‚  ML Orchestratorâ”‚â”€â”€â”€â–¶â”‚ Anomaly Detectorâ”‚
â”‚   (Log Input)   â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Agent     â”‚â—€â”€â”€â”€â”‚  Orchestrator   â”‚â”€â”€â”€â–¶â”‚ Mitigation Agentâ”‚
â”‚ (Knowledge Base)â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Critical LLM    â”‚    â”‚ Report Gen.     â”‚    â”‚ Paging Agent    â”‚
â”‚ Agent           â”‚    â”‚ Agent           â”‚    â”‚ (Twilio)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Environment Variables

This project uses environment variables to manage sensitive configuration like API keys and credentials. 

### Setup Instructions

1. **Copy the example environment file:**
   ```bash
   cp .env.example .env
   ```

2. **Edit the `.env` file with your actual credentials:**
   ```bash
   # OpenAI API Configuration
   OPENAI_API_KEY=your-actual-openai-api-key
   
   # Twilio Configuration (for phone paging)
   TWILIO_ACCOUNT_SID=your-twilio-account-sid
   TWILIO_AUTH_TOKEN=your-twilio-auth-token
   TWILIO_FROM_NUMBER=your-twilio-from-number
   SRE_ONCALL_PHONE=your-oncall-phone-number
   
   # SendGrid Configuration (for email reports)
   SENDGRID_API_KEY=your-sendgrid-api-key
   SRE_SENDER_EMAIL=your-sender-email
   SRE_RECIPIENT_EMAIL=your-recipient-email
   
   # Database Configuration
   POSTGRES_PASSWORD=your-postgres-password
   ```

3. **Important:** The `.env` file is ignored by git to keep your secrets safe. Never commit your actual API keys!

### Required Services

- **OpenAI API**: For LLM-powered analysis and recommendations
- **Twilio**: For phone call notifications (optional)
- **SendGrid**: For email report delivery (optional)
- **PostgreSQL**: For data persistence (optional)

## ğŸ“ Project Structure

```
Aegis---Intelligent-SRE-Agent/
â”œâ”€â”€ orchestration/          # Core orchestration engine
â”‚   â”œâ”€â”€ ml_orchestrator.py  # ML model orchestration
â”‚   â”œâ”€â”€ sre_agent_orchestrator.py  # Main SRE orchestrator
â”‚   â”œâ”€â”€ validation_simulator.py    # Mitigation validation
â”‚   â””â”€â”€ config.py           # Orchestration configuration
â”œâ”€â”€ agents/                 # Individual agent implementations
â”‚   â”œâ”€â”€ anomaly_detector_agent.py  # ML-based anomaly detection
â”‚   â”œâ”€â”€ rag_agent.py        # RAG knowledge retrieval
â”‚   â”œâ”€â”€ mitigation_agent.py # Automated mitigation
â”‚   â”œâ”€â”€ advanced_llm_agent.py      # Critical issue analysis
â”‚   â”œâ”€â”€ report_generation_agent.py # Email report generation
â”‚   â”œâ”€â”€ paging_agent.py     # Twilio phone paging
â”‚   â””â”€â”€ __init__.py         # Agent package initialization
â”œâ”€â”€ ml_pipeline/            # ML models and training
â”‚   â”œâ”€â”€ anomaly_detector.py # ML pipeline for anomaly detection
â”‚   â”œâ”€â”€ saved_models/       # Trained model files
â”‚   â””â”€â”€ notebooks/          # Jupyter notebooks for exploration
â”œâ”€â”€ streaming/              # Kafka integration
â”‚   â””â”€â”€ kafka/              # Kafka streaming components
â”‚       â””â”€â”€ custom_log_streamer.py
â”œâ”€â”€ communications/         # Voice and email systems
â”‚   â”œâ”€â”€ eleven_labs/        # Voice synthesis (future)
â”‚   â””â”€â”€ twilio/             # Call and email delivery (future)
â”œâ”€â”€ frontend/               # Dashboard UI
â”‚   â”œâ”€â”€ index.html          # Main dashboard
â”‚   â”œâ”€â”€ styles.css          # Dashboard styling
â”‚   â””â”€â”€ js/                 # JavaScript components
â”œâ”€â”€ data/                   # Synthetic data and knowledge base
â”‚   â”œâ”€â”€ knowledge_base/     # RAG knowledge base
â”‚   â”œâ”€â”€ logs.json           # Sample log data
â”‚   â”œâ”€â”€ metadata.json       # System metadata
â”‚   â””â”€â”€ playbooks/          # Mitigation playbooks
â”œâ”€â”€ tests/                  # Test suites
â”‚   â”œâ”€â”€ test_complete_system.py
â”‚   â”œâ”€â”€ test_ml_orchestrator.py
â”‚   â”œâ”€â”€ test_rag_agent.py
â”‚   â””â”€â”€ test_streaming.py
â”œâ”€â”€ config/                 # Configuration files
â”‚   â””â”€â”€ sre_agent_config.json
â”œâ”€â”€ scripts/                # Setup and utility scripts
â”‚   â”œâ”€â”€ init_db.sql         # Database initialization
â”‚   â”œâ”€â”€ install.sh          # Installation script
â”‚   â””â”€â”€ cleanup.sh          # Cleanup utilities
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ README_DASHBOARD.md
â”‚   â”œâ”€â”€ README_SRE_AGENT.md
â”‚   â”œâ”€â”€ KAFKA_SETUP_GUIDE.md
â”‚   â””â”€â”€ INTEGRATION.md
â”œâ”€â”€ config/docker-compose.yml      # Infrastructure setup
â”œâ”€â”€ config/requirements.txt        # Python dependencies
â”œâ”€â”€ config/requirements-dashboard.txt
â”œâ”€â”€ config/requirements-streaming.txt
â”œâ”€â”€ orchestration/config.py        # Main configuration
â”œâ”€â”€ orchestration/dashboard_server.py     # Dashboard server
â”œâ”€â”€ orchestration/dashboard_server_simple.py
â”œâ”€â”€ scripts/start_dashboard.sh      # Dashboard startup script
â”œâ”€â”€ scripts/start_sre_agent.sh      # SRE agent startup script
â”œâ”€â”€ scripts/start_streaming.sh      # Streaming startup script
â””â”€â”€ README.md                       # This file
```

## ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Docker & Docker Compose** (for Kafka infrastructure)
- **OpenAI API Key** (for RAG and LLM agents)
- **Twilio Account** (for paging functionality)
- **SendGrid Account** (for email reports)
- **8GB+ RAM** (for ML model inference)
- **macOS/Linux** (tested on macOS 22.6.0)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone <repository-url>
cd Aegis---Intelligent-SRE-Agent
```

### 2. Install Dependencies

```bash
# Install Python dependencies
pip install -r config/requirements.txt
pip install -r config/requirements-dashboard.txt
pip install -r config/requirements-streaming.txt

# Or use the automated installer
chmod +x scripts/install.sh
./scripts/install.sh
```

### 3. Configure API Keys

Create a `orchestration/config.py` file with your API credentials:

```python
# OpenAI Configuration
OPENAI_CONFIG = {
    'api_key': 'your-openai-api-key-here',
    'model': 'gpt-4',
    'temperature': 0.1
}

# Twilio Configuration (for paging)
TWILIO_CONFIG = {
    'account_sid': 'your-twilio-account-sid',
    'auth_token': 'your-twilio-auth-token',
    'from_number': '+1234567890',
    'to_number': '+1987654321'
}

# SendGrid Configuration (for email reports)
SENDGRID_CONFIG = {
    'api_key': 'your-sendgrid-api-key',
    'from_email': 'sre-alerts@yourcompany.com',
    'to_email': 'oncall@yourcompany.com'
}
```

### 4. Generate Synthetic Data and Train Models

```bash
# Generate training data
python orchestration/synthetic_data_generator.py --training

# Generate streaming data
python orchestration/synthetic_data_generator.py --streaming

# Train ML models
python ml_pipeline/anomaly_detector.py --train
```

### 5. Start Infrastructure

```bash
# Start Kafka, Zookeeper, Redis, and PostgreSQL
docker-compose up -d

# Wait for services to be ready (about 30 seconds)
sleep 30
```

### 6. Start the SRE Dashboard

```bash
# Start the dashboard server
python3 orchestration/dashboard_server_simple.py

# Or use the automated startup script
chmod +x scripts/start_dashboard.sh
./scripts/start_dashboard.sh
```

### 7. Access the Dashboard

Open your browser and navigate to:
```
http://localhost:8082
```

## ğŸ® Usage Guide

### Dashboard Interface

The dashboard provides several key sections:

#### ğŸ“Š **Live Metrics Panel**
- Real-time system performance metrics
- CPU, Memory, Error Rate, Latency monitoring
- Historical trend visualization

#### ğŸ” **Agent Status Panel**
- Live status of all SRE agents
- Current activity and processing state
- Agent confidence levels and decisions

#### ğŸ“ **Live Log Stream**
- Real-time log visualization
- Color-coded by severity (green=normal, red=anomaly)
- Automatic anomaly highlighting

#### ğŸ§  **Reasoning Trace**
- Step-by-step agent decision process
- Real-time reasoning updates
- Agent thought process visualization

#### ğŸ¯ **Anomaly Injection Panel**
- Manual anomaly injection for testing
- Pre-defined anomaly scenarios:
  - **CPU Overload**: High CPU usage simulation
  - **Memory Leak**: Memory exhaustion scenario
  - **Service Crash**: Critical service failure
  - **Database Issues**: Connection pool exhaustion
  - **Network Latency**: High latency simulation

### Testing the System

#### 1. **Normal Operation**
- Watch the dashboard during normal operation
- Observe green logs and "Anomaly Not Detected" status
- Monitor agent activity and reasoning trace

#### 2. **Inject Anomaly**
- Click on any anomaly preset button
- Observe the complete flow:
  1. **Anomaly Detector** (5s): ML inference and detection
  2. **RAG Agent** (5s): Knowledge base analysis
  3. **Mitigation Agent** (10s): Automated resolution
  4. **Critical Path** (if applicable): LLM analysis + Paging

#### 3. **Critical Issue Testing**
- Inject "Service Crash" anomaly
- Observe escalation to Critical Anomaly Reasoning Agent
- Watch email report generation and phone paging

### Streaming Integration

#### Basic Streaming

```bash
# Start Kafka infrastructure
./scripts/start_streaming.sh start

# Stream your application logs
python orchestration/stream_logs_direct.py
```

#### High-Volume Streaming

```bash
# Stream at higher rates using the integration service
python orchestration/streaming_integration.py --mode normal --rate 10 --duration 60 --kafka-servers 127.0.0.1:9093
```

#### Burst Mode (Simulate High Load)

```bash
# Stream in bursts to simulate traffic spikes
python orchestration/streaming_integration.py --mode burst --rate 20 --duration 30 --kafka-servers 127.0.0.1:9093
```

## ğŸ”§ Configuration

### Environment Variables

```bash
export OPENAI_API_KEY="your-openai-key"
export TWILIO_ACCOUNT_SID="your-twilio-sid"
export TWILIO_AUTH_TOKEN="your-twilio-token"
export SENDGRID_API_KEY="your-sendgrid-key"
```

### Kafka Configuration

The system uses Kafka for log streaming. Default configuration:

```yaml
# docker-compose.yml
kafka:
  ports:
    - "9092:9092"  # Kafka broker
  environment:
    KAFKA_NUM_PARTITIONS: 3
    KAFKA_LOG_RETENTION_HOURS: 24
```

### ML Model Configuration

```python
# config.py
ML_CONFIG = {
    'model_path': 'ml_pipeline/saved_models/',
    'anomaly_threshold': 0.7,
    'batch_size': 100,
    'update_interval': 30
}
```

## ğŸ§ª Testing

### Run Complete System Test

```bash
python3 tests/test_complete_system.py
```

### Test Individual Components

```bash
# Test ML Orchestrator
python3 tests/test_ml_orchestrator.py

# Test RAG Agent
python3 tests/test_rag_agent.py

# Test Mitigation Agent
python3 tests/test_streaming.py
```

### Manual Testing via Dashboard

1. **Start the dashboard**: `python3 dashboard_server_simple.py`
2. **Open browser**: Navigate to `http://localhost:8082`
3. **Inject anomalies**: Use the preset buttons
4. **Monitor flow**: Watch the reasoning trace and agent activity
5. **Check results**: Verify email reports and phone calls

## ğŸ“Š Log Format

The system works with structured JSON logs:

```json
{
  "service": "user-service",
  "level": "INFO",
  "host": "user-service-1.prod.internal",
  "message": "User login successful",
  "metrics": {
    "cpu_usage": 45.2,
    "memory_usage": 52.1,
    "error_rate": 0.002,
    "request_latency_ms": 120,
    "active_connections": 50
  },
  "anomaly": false
}
```

## ğŸ” Troubleshooting

### Common Issues

#### 1. **Dashboard Not Loading**
```bash
# Check if server is running
curl http://localhost:8082/api/health

# Restart server
pkill -f dashboard_server_simple
python3 dashboard_server_simple.py
```

#### 2. **Kafka Connection Issues**
```bash
# Check Kafka status
docker-compose ps

# Restart Kafka
docker-compose restart kafka

# Check logs
docker-compose logs kafka
```

#### 3. **API Key Issues**
```bash
# Verify configuration
python3 -c "import config; print('Config loaded successfully')"

# Check environment variables
echo $OPENAI_API_KEY
```

#### 4. **ML Model Issues**
```bash
# Check model files
ls -la ml_pipeline/saved_models/

# Test ML orchestrator
python3 tests/test_ml_orchestrator.py
```

### Debug Commands

```bash
# View all logs
tail -f logs/dashboard.log

# Check running processes
ps aux | grep python

# Monitor system resources
htop

# Check Docker containers
docker-compose ps
```

## ğŸš€ Production Deployment

### Docker Deployment

```bash
# Build production image
docker build -t aegis-sre-agent .

# Run with production config
docker run -d \
  -p 8082:8082 \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -e TWILIO_ACCOUNT_SID=$TWILIO_ACCOUNT_SID \
  aegis-sre-agent
```

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aegis-sre-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: aegis-sre-agent
  template:
    metadata:
      labels:
        app: aegis-sre-agent
    spec:
      containers:
      - name: aegis-sre-agent
        image: aegis-sre-agent:latest
        ports:
        - containerPort: 8082
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: aegis-secrets
              key: openai-api-key
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes
4. Add tests for new functionality
5. Commit your changes: `git commit -am 'Add feature'`
6. Push to the branch: `git push origin feature-name`
7. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI** for GPT-4 integration
- **Twilio** for phone paging capabilities
- **SendGrid** for email delivery
- **Apache Kafka** for real-time streaming
- **Scikit-learn** for ML capabilities

## ğŸ“ Support

For support and questions:
- **Email**: sre-support@yourcompany.com
- **Slack**: #sre-agent-support
- **Documentation**: [Wiki Link]

---

